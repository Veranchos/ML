{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv',sep = '\\t', quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "test = pd.read_csv('test.csv',sep = '\\t', quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "dev = pd.read_csv('dev.csv',sep = '\\t', quoting=csv.QUOTE_NONE, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "Примеров класса 1:  2425\n",
      "Примеров класса 0:  4900 \n",
      "\n",
      "test:\n",
      "Примеров класса 1:  680\n",
      "Примеров класса 0:  1365 \n",
      "\n",
      "dev:\n",
      "Примеров класса 1:  956\n",
      "Примеров класса 0:  1981 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('train:')\n",
    "print('Примеров класса 1: ', int(train['class'].sum()))\n",
    "print('Примеров класса 0: ', int(len(train['class'])-train['class'].sum()), '\\n')\n",
    "print('test:')\n",
    "print('Примеров класса 1: ', int(test['class'].sum()))\n",
    "print('Примеров класса 0: ', int(len(test['class'])-test['class'].sum()), '\\n')\n",
    "print('dev:')\n",
    "print('Примеров класса 1: ', int(dev['class'].sum()))\n",
    "print('Примеров класса 0: ', int(len(dev['class'])-dev['class'].sum()), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Анализ разметки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = train[train['class'] != 0]\n",
    "test_1 = test[test['class'] != 0]\n",
    "dev_1 = dev[dev['class'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "strange_cases = pd.DataFrame(columns=['text', 'class', 'cV', 'cR1', 'cR2', 'V', 'R1', 'R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pattern = re.compile(r'^(\\d+:\\d+)$')\n",
    "\n",
    "for index, row in test_1.loc[:,'cV':].iterrows():\n",
    "    for i in row:\n",
    "        if not re.match(pattern, str(i)):\n",
    "            strange_cases = strange_cases.append(test_1.loc[index])\n",
    "\n",
    "for index, row in train_1.loc[:,'cV':].iterrows():\n",
    "    for i in row:\n",
    "        if not re.match(pattern, str(i)):\n",
    "            strange_cases = strange_cases.append(train_1.loc[index])\n",
    "            \n",
    "for index, row in dev_1.loc[:,'cV':].iterrows():\n",
    "    for i in row:\n",
    "        if not re.match(pattern, str(i)):\n",
    "            strange_cases = strange_cases.append(dev_1.loc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Друзья делают твой смех немного громче, твою у...</td>\n",
       "      <td>1</td>\n",
       "      <td>7:13</td>\n",
       "      <td>14:23</td>\n",
       "      <td>24:38</td>\n",
       "      <td>52:52 79:79</td>\n",
       "      <td>40:51 68:78</td>\n",
       "      <td>52:64 79:92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>При этом один из этих выводов используется для...</td>\n",
       "      <td>1</td>\n",
       "      <td>30:42</td>\n",
       "      <td>9:29</td>\n",
       "      <td>43:59</td>\n",
       "      <td>68:68 92:92</td>\n",
       "      <td>61:67 82:91</td>\n",
       "      <td>68:78 92:175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>- Невеста притворяется, что она девственница, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10:22</td>\n",
       "      <td>2:9</td>\n",
       "      <td>24:44</td>\n",
       "      <td>54:54 109:109</td>\n",
       "      <td>46:51 83:106</td>\n",
       "      <td>54:81 109:132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Его деликатность была объявлена лицемерием, ег...</td>\n",
       "      <td>1</td>\n",
       "      <td>22:31</td>\n",
       "      <td>0:16</td>\n",
       "      <td>32:42</td>\n",
       "      <td>73:73 107:107</td>\n",
       "      <td>44:70 91:104</td>\n",
       "      <td>73:89 107:121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>В бумажнике я обнаружил упаковку с тремя презе...</td>\n",
       "      <td>1</td>\n",
       "      <td>14:23</td>\n",
       "      <td>0:11</td>\n",
       "      <td>24:55</td>\n",
       "      <td>78:78 114:114</td>\n",
       "      <td>57:75 102:111</td>\n",
       "      <td>78:98 114:135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text class     cV    cR1  \\\n",
       "23   Друзья делают твой смех немного громче, твою у...     1   7:13  14:23   \n",
       "126  При этом один из этих выводов используется для...     1  30:42   9:29   \n",
       "175  - Невеста притворяется, что она девственница, ...     1  10:22    2:9   \n",
       "206  Его деликатность была объявлена лицемерием, ег...     1  22:31   0:16   \n",
       "230  В бумажнике я обнаружил упаковку с тремя презе...     1  14:23   0:11   \n",
       "\n",
       "       cR2              V             R1             R2  \n",
       "23   24:38    52:52 79:79    40:51 68:78    52:64 79:92  \n",
       "126  43:59    68:68 92:92    61:67 82:91   68:78 92:175  \n",
       "175  24:44  54:54 109:109   46:51 83:106  54:81 109:132  \n",
       "206  32:42  73:73 107:107   44:70 91:104  73:89 107:121  \n",
       "230  24:55  78:78 114:114  57:75 102:111  78:98 114:135  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strange_cases = strange_cases.drop_duplicates()\n",
    "strange_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_pairs = strange_cases.dropna(how='any')\n",
    "multiple_pairs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В большинстве случаев, отклоняющихся от нормы (274), в ячейках содержится по две и более пар оффсетов, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Именно поэтому прогресс в данном случае ассоциировался прежде всего с индустриальной экспансией, богатство — с накоплением финансовых резервов, а хозяйственный потенциал — с массой основных производственных фондов и доступных естественных ресурсов.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strange_cases['text'][368]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предикат _ассоциировался_ пропущен дважды\n",
    "\n",
    "Ещё пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'По сравнению с декабрем 2005 г. индекс Доу-Джонса возрос на 2,9%, Xetra DAX-30 — на 9,7%, CAC-40 — на 8,8%, FTSE-100 — на 7,1%, Nikkei 225 — на 4,2%, Hang Seng — на 4,4%.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_pairs['text'][600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'81:81 99:99 119:119 141:141 162:162'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_pairs['V'][600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "предикат _возрос_ опущен 5 раз\n",
    "\n",
    "Посмотрим на другие случаи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "other_cases = pd.DataFrame(columns=['text', 'class', 'cV', 'cR1', 'cR2', 'V', 'R1', 'R2'])\n",
    "for index, row in strange_cases.iterrows():\n",
    "    for i in row:\n",
    "        if 'nan' in str(i):\n",
    "            other_cases = other_cases.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_cases = other_cases.drop_duplicates()\n",
    "other_cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 предложения оказались неразмеченными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     Он с трудом передвигается на ногах, как если б...\n",
      "class                                                  NaN\n",
      "cV                                                     NaN\n",
      "cR1                                                    NaN\n",
      "cR2                                                    NaN\n",
      "V                                                      NaN\n",
      "R1                                                     NaN\n",
      "R2                                                     NaN\n",
      "Name: 7324, dtype: object\n",
      "text     в июне 2011 года по сравнению с декабр\n",
      "class                                       NaN\n",
      "cV                                          NaN\n",
      "cR1                                         NaN\n",
      "cR2                                         NaN\n",
      "V                                           NaN\n",
      "R1                                          NaN\n",
      "R2                                          NaN\n",
      "Name: 2936, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index, row in other_cases.iterrows():\n",
    "    if str(row['class']) == 'nan':\n",
    "        print(row)\n",
    "        other_cases = other_cases.drop(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В остальных случаях пропущены cR2 и, соответсвенно, R2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!!!!!Здесь требуется мнение экспертов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Девушка поднимает глаза, смотрит на Нэша, потом – на меня.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_cases['text'][1262]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае субъект действия _девушка_ находится в другой клаузе **ЭТО НОРМ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Переступив через порог, я обнаружил небольшую площадку, спиральную лестницу, а наверху — стойку с инструментами в каменной будке.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_cases['text'][852]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Здесь вообще всё хорошо,ничё не понимаю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for index, row in other_cases.iterrows():\n",
    "    if str(row['cR2']) == 'nan':\n",
    "        other_cases = other_cases.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_cases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Других случаев нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = pd.DataFrame([['Две и более пары оффсетов', '274', strange_cases['text'][543]],\\\n",
    "                        ['Отсутствует cR2', '83', strange_cases['text'][1853]],\\\n",
    "                        ['Предложение не размечено', '2', strange_cases['text'][2936]]],\n",
    "                        columns = ['Описание кейса', 'Количество случаев', 'Пример'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Описание кейса</th>\n",
       "      <th>Количество случаев</th>\n",
       "      <th>Пример</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Две и более пары оффсетов</td>\n",
       "      <td>274</td>\n",
       "      <td>В садике я мечтала о школе, в школе — об инсти...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Отсутствует cR2</td>\n",
       "      <td>83</td>\n",
       "      <td>Гарри в замешательстве уставился на Дамблдора,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Предложение не размечено</td>\n",
       "      <td>2</td>\n",
       "      <td>в июне 2011 года по сравнению с декабр</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Описание кейса Количество случаев  \\\n",
       "0  Две и более пары оффсетов                274   \n",
       "1            Отсутствует cR2                 83   \n",
       "2   Предложение не размечено                  2   \n",
       "\n",
       "                                              Пример  \n",
       "0  В садике я мечтала о школе, в школе — об инсти...  \n",
       "1  Гарри в замешательстве уставился на Дамблдора,...  \n",
       "2             в июне 2011 года по сравнению с декабр  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Бинарная классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim import models\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from string import punctuation\n",
    "\n",
    "punct = punctuation+'«»—…“”*№–'\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in train.iterrows():\n",
    "    if str(row['class']) == 'nan':\n",
    "        train = train.drop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = models.KeyedVectors.load_word2vec_format(r'C:\\Users\\a.reshetniko\\Documents\\trash\\ml\\ML\\HW2\\180\\model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    out = []\n",
    "    words = [word.strip(punct) for word in text.lower().split()] \n",
    "    for word in words:\n",
    "        if word:\n",
    "            output = '%s_%s' % (morph.parse(word)[0].normal_form, morph.parse(word)[0].tag.POS)\n",
    "            out.append(output)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=embeddings\n",
    "def get_vector(sent):\n",
    "    vector = np.zeros(shape=model.vector_size)\n",
    "    counter = 0\n",
    "    for word in sent:\n",
    "        if word in model.vocab: \n",
    "            try:\n",
    "                vector = np.add(vector, model[word])\n",
    "                counter += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    if counter == 0:\n",
    "        return vector\n",
    "    return vector / counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['lemmas'] = train['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'vector_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-58ae9aba9790>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vectors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lemmas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3192\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3194\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-9b9c74c205a7>\u001b[0m in \u001b[0;36mget_vector\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mvector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 535\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'vector_size'"
     ]
    }
   ],
   "source": [
    "train['vectors'] = train['lemmas'].apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Будучи в прошлый четверг в Софии, он назвал се...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[быть_GRND, в_PREP, прошлый_ADJF, четверг_NOUN...</td>\n",
       "      <td>[0.168603191152215, -0.28739759884774685, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Работа с двухбайтовыми наборами символов — про...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92:99</td>\n",
       "      <td>83:91</td>\n",
       "      <td>103:109</td>\n",
       "      <td>127:127</td>\n",
       "      <td>119:124</td>\n",
       "      <td>127:134</td>\n",
       "      <td>[работа_NOUN, с_PREP, двухбайтовый_ADJF, набор...</td>\n",
       "      <td>[0.4240986340575748, 0.13711692641178766, 1.37...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Заместитель Генерального секретаря подчеркнул,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[заместитель_NOUN, генеральный_ADJF, секретари...</td>\n",
       "      <td>[0.09843469476875137, -0.1834418819669415, 1.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Продажа недвижимости из собственных портфелей ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[продажа_NOUN, недвижимость_NOUN, из_PREP, соб...</td>\n",
       "      <td>[-0.15080114901065828, -0.33817869424819946, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Новым является то, что повышенное давление кон...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[новый_ADJF, являться_VERB, то_CONJ, что_CONJ,...</td>\n",
       "      <td>[1.0187650003481838, -0.013968473164046683, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV    cR1  \\\n",
       "0  Будучи в прошлый четверг в Софии, он назвал се...    0.0    NaN    NaN   \n",
       "1  Работа с двухбайтовыми наборами символов — про...    1.0  92:99  83:91   \n",
       "2  Заместитель Генерального секретаря подчеркнул,...    0.0    NaN    NaN   \n",
       "3  Продажа недвижимости из собственных портфелей ...    0.0    NaN    NaN   \n",
       "4  Новым является то, что повышенное давление кон...    0.0    NaN    NaN   \n",
       "\n",
       "       cR2        V       R1       R2  \\\n",
       "0      NaN      NaN      NaN      NaN   \n",
       "1  103:109  127:127  119:124  127:134   \n",
       "2      NaN      NaN      NaN      NaN   \n",
       "3      NaN      NaN      NaN      NaN   \n",
       "4      NaN      NaN      NaN      NaN   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [быть_GRND, в_PREP, прошлый_ADJF, четверг_NOUN...   \n",
       "1  [работа_NOUN, с_PREP, двухбайтовый_ADJF, набор...   \n",
       "2  [заместитель_NOUN, генеральный_ADJF, секретари...   \n",
       "3  [продажа_NOUN, недвижимость_NOUN, из_PREP, соб...   \n",
       "4  [новый_ADJF, являться_VERB, то_CONJ, что_CONJ,...   \n",
       "\n",
       "                                             vectors  \n",
       "0  [0.168603191152215, -0.28739759884774685, 0.09...  \n",
       "1  [0.4240986340575748, 0.13711692641178766, 1.37...  \n",
       "2  [0.09843469476875137, -0.1834418819669415, 1.6...  \n",
       "3  [-0.15080114901065828, -0.33817869424819946, -...  \n",
       "4  [1.0187650003481838, -0.013968473164046683, 0....  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'MLELoss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-0e53cb948a7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mloss_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMLELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'MLELoss'"
     ]
    }
   ],
   "source": [
    "X = torch.tensor(train['vectors']).float()\n",
    "Y = torch.tensor(train['class']).float()\n",
    "\n",
    "D_in, H, D_out = X.shape[1], 100, 1\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "loss_fn = torch.nn.MLELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 23270062.0\n",
      "1 23270062.0\n",
      "2 23270062.0\n",
      "3 23270062.0\n",
      "4 23270062.0\n",
      "5 23270062.0\n",
      "6 23270062.0\n",
      "7 23270062.0\n",
      "8 23270062.0\n",
      "9 23270062.0\n",
      "10 23270062.0\n",
      "11 23270062.0\n",
      "12 23270062.0\n",
      "13 23270062.0\n",
      "14 23270062.0\n",
      "15 23270062.0\n",
      "16 23270062.0\n",
      "17 23270062.0\n",
      "18 23270062.0\n",
      "19 23270062.0\n",
      "20 23270062.0\n",
      "21 23270062.0\n",
      "22 23270062.0\n",
      "23 23270062.0\n",
      "24 23270062.0\n",
      "25 23270062.0\n",
      "26 23270062.0\n",
      "27 23270062.0\n",
      "28 23270062.0\n",
      "29 23270062.0\n",
      "30 23270062.0\n",
      "31 23270062.0\n",
      "32 23270062.0\n",
      "33 23270062.0\n",
      "34 23270062.0\n",
      "35 23270062.0\n",
      "36 23270062.0\n",
      "37 23270062.0\n",
      "38 23270062.0\n",
      "39 23270062.0\n",
      "40 23270062.0\n",
      "41 23270062.0\n",
      "42 23270062.0\n",
      "43 23270062.0\n",
      "44 23270062.0\n",
      "45 23270062.0\n",
      "46 23270062.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-1f53ac8dcb85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36ml1_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2135\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(1000):\n",
    "    y_pred = model(X)\n",
    "    \n",
    "    loss = loss_fn(y_pred, Y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "print(y.shape)\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use Adam; the optim package contains many other\n",
    "# optimization algoriths. The first argument to the Adam constructor tells the\n",
    "# optimizer which Tensors it should update.\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 753.6369018554688\n",
      "1 735.5465698242188\n",
      "2 717.9341430664062\n",
      "3 700.8726806640625\n",
      "4 684.3085327148438\n",
      "5 668.2918701171875\n",
      "6 652.7163696289062\n",
      "7 637.6962280273438\n",
      "8 622.9942626953125\n",
      "9 608.650634765625\n",
      "10 594.69873046875\n",
      "11 581.1485595703125\n",
      "12 567.9405517578125\n",
      "13 555.11474609375\n",
      "14 542.700439453125\n",
      "15 530.5648193359375\n",
      "16 518.720947265625\n",
      "17 507.1903076171875\n",
      "18 496.0260009765625\n",
      "19 485.26275634765625\n",
      "20 474.8309631347656\n",
      "21 464.7048034667969\n",
      "22 454.85565185546875\n",
      "23 445.21282958984375\n",
      "24 435.84033203125\n",
      "25 426.68408203125\n",
      "26 417.7660217285156\n",
      "27 409.02783203125\n",
      "28 400.4787902832031\n",
      "29 392.15350341796875\n",
      "30 384.0176086425781\n",
      "31 376.04901123046875\n",
      "32 368.2317810058594\n",
      "33 360.5740661621094\n",
      "34 353.1531982421875\n",
      "35 345.89764404296875\n",
      "36 338.76068115234375\n",
      "37 331.7475280761719\n",
      "38 324.87176513671875\n",
      "39 318.1094665527344\n",
      "40 311.4885559082031\n",
      "41 304.9706115722656\n",
      "42 298.5879211425781\n",
      "43 292.3129577636719\n",
      "44 286.14691162109375\n",
      "45 280.1170349121094\n",
      "46 274.2104797363281\n",
      "47 268.4420471191406\n",
      "48 262.76983642578125\n",
      "49 257.1952209472656\n",
      "50 251.7279052734375\n",
      "51 246.35964965820312\n",
      "52 241.0821990966797\n",
      "53 235.88853454589844\n",
      "54 230.77735900878906\n",
      "55 225.75927734375\n",
      "56 220.82847595214844\n",
      "57 215.97442626953125\n",
      "58 211.20188903808594\n",
      "59 206.5060577392578\n",
      "60 201.8912353515625\n",
      "61 197.3524627685547\n",
      "62 192.90069580078125\n",
      "63 188.53224182128906\n",
      "64 184.24273681640625\n",
      "65 180.03387451171875\n",
      "66 175.90399169921875\n",
      "67 171.8451690673828\n",
      "68 167.83807373046875\n",
      "69 163.9091339111328\n",
      "70 160.046142578125\n",
      "71 156.25299072265625\n",
      "72 152.52886962890625\n",
      "73 148.86245727539062\n",
      "74 145.2694549560547\n",
      "75 141.74598693847656\n",
      "76 138.29574584960938\n",
      "77 134.91046142578125\n",
      "78 131.58714294433594\n",
      "79 128.32504272460938\n",
      "80 125.1280288696289\n",
      "81 121.9964828491211\n",
      "82 118.92942810058594\n",
      "83 115.92454528808594\n",
      "84 112.96835327148438\n",
      "85 110.07331848144531\n",
      "86 107.23652648925781\n",
      "87 104.45826721191406\n",
      "88 101.74186706542969\n",
      "89 99.07870483398438\n",
      "90 96.46504211425781\n",
      "91 93.91260528564453\n",
      "92 91.41114807128906\n",
      "93 88.96878051757812\n",
      "94 86.58126831054688\n",
      "95 84.24261474609375\n",
      "96 81.96045684814453\n",
      "97 79.72544860839844\n",
      "98 77.54629516601562\n",
      "99 75.41229248046875\n",
      "100 73.32620239257812\n",
      "101 71.28626251220703\n",
      "102 69.2947769165039\n",
      "103 67.34963989257812\n",
      "104 65.44945526123047\n",
      "105 63.5921630859375\n",
      "106 61.779022216796875\n",
      "107 60.00876998901367\n",
      "108 58.2802734375\n",
      "109 56.59403991699219\n",
      "110 54.94890213012695\n",
      "111 53.34592056274414\n",
      "112 51.78223419189453\n",
      "113 50.258853912353516\n",
      "114 48.774837493896484\n",
      "115 47.32979202270508\n",
      "116 45.91922378540039\n",
      "117 44.546695709228516\n",
      "118 43.207672119140625\n",
      "119 41.906341552734375\n",
      "120 40.63793182373047\n",
      "121 39.40290069580078\n",
      "122 38.20307922363281\n",
      "123 37.034820556640625\n",
      "124 35.897220611572266\n",
      "125 34.792083740234375\n",
      "126 33.71757507324219\n",
      "127 32.673709869384766\n",
      "128 31.65749740600586\n",
      "129 30.668258666992188\n",
      "130 29.707111358642578\n",
      "131 28.77230453491211\n",
      "132 27.862089157104492\n",
      "133 26.97674560546875\n",
      "134 26.11502456665039\n",
      "135 25.277355194091797\n",
      "136 24.464479446411133\n",
      "137 23.674118041992188\n",
      "138 22.906803131103516\n",
      "139 22.161914825439453\n",
      "140 21.437471389770508\n",
      "141 20.73501205444336\n",
      "142 20.052898406982422\n",
      "143 19.39048957824707\n",
      "144 18.747770309448242\n",
      "145 18.125789642333984\n",
      "146 17.522193908691406\n",
      "147 16.937593460083008\n",
      "148 16.37023162841797\n",
      "149 15.820638656616211\n",
      "150 15.288411140441895\n",
      "151 14.7725191116333\n",
      "152 14.272244453430176\n",
      "153 13.788169860839844\n",
      "154 13.319866180419922\n",
      "155 12.866398811340332\n",
      "156 12.427472114562988\n",
      "157 12.002728462219238\n",
      "158 11.591270446777344\n",
      "159 11.193183898925781\n",
      "160 10.807591438293457\n",
      "161 10.434361457824707\n",
      "162 10.073612213134766\n",
      "163 9.723814010620117\n",
      "164 9.385273933410645\n",
      "165 9.058146476745605\n",
      "166 8.741792678833008\n",
      "167 8.435470581054688\n",
      "168 8.139335632324219\n",
      "169 7.854030609130859\n",
      "170 7.578185081481934\n",
      "171 7.311908721923828\n",
      "172 7.053626537322998\n",
      "173 6.804006576538086\n",
      "174 6.5627288818359375\n",
      "175 6.329434394836426\n",
      "176 6.103597640991211\n",
      "177 5.885631084442139\n",
      "178 5.674657344818115\n",
      "179 5.470799922943115\n",
      "180 5.273752689361572\n",
      "181 5.083267688751221\n",
      "182 4.8989973068237305\n",
      "183 4.7210373878479\n",
      "184 4.548884868621826\n",
      "185 4.382714748382568\n",
      "186 4.221972942352295\n",
      "187 4.066756725311279\n",
      "188 3.9168426990509033\n",
      "189 3.7719268798828125\n",
      "190 3.6320323944091797\n",
      "191 3.4969637393951416\n",
      "192 3.3664276599884033\n",
      "193 3.2402195930480957\n",
      "194 3.1182992458343506\n",
      "195 3.000427484512329\n",
      "196 2.8865723609924316\n",
      "197 2.7766270637512207\n",
      "198 2.6702842712402344\n",
      "199 2.56771183013916\n",
      "200 2.4686360359191895\n",
      "201 2.3729162216186523\n",
      "202 2.2806296348571777\n",
      "203 2.1915462017059326\n",
      "204 2.105518102645874\n",
      "205 2.022585391998291\n",
      "206 1.9425079822540283\n",
      "207 1.8653733730316162\n",
      "208 1.7909644842147827\n",
      "209 1.7192692756652832\n",
      "210 1.6503554582595825\n",
      "211 1.5839558839797974\n",
      "212 1.5200653076171875\n",
      "213 1.4585028886795044\n",
      "214 1.3992477655410767\n",
      "215 1.3421521186828613\n",
      "216 1.287251591682434\n",
      "217 1.2344775199890137\n",
      "218 1.1835744380950928\n",
      "219 1.1346678733825684\n",
      "220 1.0876590013504028\n",
      "221 1.0424137115478516\n",
      "222 0.9989227056503296\n",
      "223 0.9571320414543152\n",
      "224 0.9169060587882996\n",
      "225 0.8782990574836731\n",
      "226 0.8411790728569031\n",
      "227 0.8055359721183777\n",
      "228 0.7712892293930054\n",
      "229 0.7383896112442017\n",
      "230 0.7067800760269165\n",
      "231 0.6764460206031799\n",
      "232 0.6473227739334106\n",
      "233 0.6193566918373108\n",
      "234 0.5925145149230957\n",
      "235 0.5667441487312317\n",
      "236 0.5420266389846802\n",
      "237 0.5183199048042297\n",
      "238 0.49554985761642456\n",
      "239 0.47371619939804077\n",
      "240 0.45278459787368774\n",
      "241 0.43273094296455383\n",
      "242 0.41348233819007874\n",
      "243 0.3950299322605133\n",
      "244 0.37736696004867554\n",
      "245 0.3604259788990021\n",
      "246 0.344214528799057\n",
      "247 0.3286808729171753\n",
      "248 0.3138008415699005\n",
      "249 0.2995465099811554\n",
      "250 0.2859209179878235\n",
      "251 0.2728458642959595\n",
      "252 0.26035991311073303\n",
      "253 0.24849945306777954\n",
      "254 0.2371305227279663\n",
      "255 0.22625569999217987\n",
      "256 0.21585683524608612\n",
      "257 0.20589490234851837\n",
      "258 0.1963769942522049\n",
      "259 0.18727515637874603\n",
      "260 0.1785784810781479\n",
      "261 0.1702478677034378\n",
      "262 0.16229331493377686\n",
      "263 0.1546894609928131\n",
      "264 0.1474272459745407\n",
      "265 0.14048923552036285\n",
      "266 0.1338547021150589\n",
      "267 0.12752339243888855\n",
      "268 0.12147603183984756\n",
      "269 0.11570343375205994\n",
      "270 0.11018919944763184\n",
      "271 0.10492976754903793\n",
      "272 0.09990537911653519\n",
      "273 0.09511284530162811\n",
      "274 0.09053885191679001\n",
      "275 0.08617459237575531\n",
      "276 0.08201667666435242\n",
      "277 0.07804121822118759\n",
      "278 0.07425626367330551\n",
      "279 0.07064653187990189\n",
      "280 0.06720226258039474\n",
      "281 0.06391918659210205\n",
      "282 0.06078995391726494\n",
      "283 0.05780753120779991\n",
      "284 0.0549672394990921\n",
      "285 0.0522594153881073\n",
      "286 0.04967896640300751\n",
      "287 0.047222841531038284\n",
      "288 0.04488198831677437\n",
      "289 0.04265275597572327\n",
      "290 0.040529701858758926\n",
      "291 0.038508884608745575\n",
      "292 0.03658614680171013\n",
      "293 0.03475401923060417\n",
      "294 0.033008940517902374\n",
      "295 0.03134990856051445\n",
      "296 0.02977115660905838\n",
      "297 0.028268985450267792\n",
      "298 0.02683919481933117\n",
      "299 0.025479314848780632\n",
      "300 0.02418549917638302\n",
      "301 0.022955788299441338\n",
      "302 0.021785883232951164\n",
      "303 0.020673463121056557\n",
      "304 0.019617944955825806\n",
      "305 0.018613973632454872\n",
      "306 0.017659682780504227\n",
      "307 0.016753247007727623\n",
      "308 0.01589200086891651\n",
      "309 0.015073095448315144\n",
      "310 0.014295287430286407\n",
      "311 0.013556881807744503\n",
      "312 0.012855330482125282\n",
      "313 0.01218825951218605\n",
      "314 0.011555408127605915\n",
      "315 0.01095426082611084\n",
      "316 0.010384157299995422\n",
      "317 0.009841793216764927\n",
      "318 0.009327370673418045\n",
      "319 0.008839076384902\n",
      "320 0.00837614294141531\n",
      "321 0.007935918867588043\n",
      "322 0.00751850800588727\n",
      "323 0.007122669368982315\n",
      "324 0.0067467233166098595\n",
      "325 0.006390075199306011\n",
      "326 0.006051869597285986\n",
      "327 0.00573105039075017\n",
      "328 0.005426846910268068\n",
      "329 0.005138210486620665\n",
      "330 0.0048646144568920135\n",
      "331 0.004605347756296396\n",
      "332 0.004360076505690813\n",
      "333 0.004127602092921734\n",
      "334 0.003907204605638981\n",
      "335 0.003698307555168867\n",
      "336 0.003500352380797267\n",
      "337 0.003312746761366725\n",
      "338 0.003134966129437089\n",
      "339 0.002966526662930846\n",
      "340 0.002807000419124961\n",
      "341 0.0026558334939181805\n",
      "342 0.002512547420337796\n",
      "343 0.00237691099755466\n",
      "344 0.002248463686555624\n",
      "345 0.0021267738193273544\n",
      "346 0.002011509845033288\n",
      "347 0.0019023856148123741\n",
      "348 0.0017990623600780964\n",
      "349 0.001701161963865161\n",
      "350 0.0016084803501144052\n",
      "351 0.0015208530239760876\n",
      "352 0.001437909435480833\n",
      "353 0.0013593920739367604\n",
      "354 0.0012851672945544124\n",
      "355 0.0012148062232881784\n",
      "356 0.0011482280679047108\n",
      "357 0.0010852321283891797\n",
      "358 0.0010256324894726276\n",
      "359 0.0009692504536360502\n",
      "360 0.0009158988832496107\n",
      "361 0.0008654263219796121\n",
      "362 0.0008176806732080877\n",
      "363 0.0007725107716396451\n",
      "364 0.0007297690608538687\n",
      "365 0.000689380569383502\n",
      "366 0.0006511695100925863\n",
      "367 0.0006150295375846326\n",
      "368 0.0005808498244732618\n",
      "369 0.0005485402652993798\n",
      "370 0.0005179944564588368\n",
      "371 0.000489098543766886\n",
      "372 0.00046180663048289716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373 0.00043599295895546675\n",
      "374 0.00041158986277878284\n",
      "375 0.0003885443729814142\n",
      "376 0.0003667446435429156\n",
      "377 0.00034614489413797855\n",
      "378 0.0003266723651904613\n",
      "379 0.00030829585739411414\n",
      "380 0.00029090585303492844\n",
      "381 0.0002745091915130615\n",
      "382 0.0002589979558251798\n",
      "383 0.000244335038587451\n",
      "384 0.00023049300943966955\n",
      "385 0.0002174216351704672\n",
      "386 0.00020508546731434762\n",
      "387 0.0001934158499352634\n",
      "388 0.0001824046776164323\n",
      "389 0.00017201420268975198\n",
      "390 0.00016218838572967798\n",
      "391 0.00015291004092432559\n",
      "392 0.00014416867634281516\n",
      "393 0.000135903712362051\n",
      "394 0.00012810710177291185\n",
      "395 0.00012074047845089808\n",
      "396 0.00011379881470929831\n",
      "397 0.00010724503954406828\n",
      "398 0.00010105101682711393\n",
      "399 9.521550964564085e-05\n",
      "400 8.971060742624104e-05\n",
      "401 8.451304893242195e-05\n",
      "402 7.960920629557222e-05\n",
      "403 7.498238846892491e-05\n",
      "404 7.062163058435544e-05\n",
      "405 6.650802970398217e-05\n",
      "406 6.26316323177889e-05\n",
      "407 5.8971825637854636e-05\n",
      "408 5.552299990085885e-05\n",
      "409 5.227192377788015e-05\n",
      "410 4.920681021758355e-05\n",
      "411 4.631404590327293e-05\n",
      "412 4.359338345238939e-05\n",
      "413 4.102364619029686e-05\n",
      "414 3.860505239572376e-05\n",
      "415 3.6325753171695396e-05\n",
      "416 3.4176759072579443e-05\n",
      "417 3.2152398489415646e-05\n",
      "418 3.0246726964833215e-05\n",
      "419 2.845134076778777e-05\n",
      "420 2.6758798412629403e-05\n",
      "421 2.5165278202621266e-05\n",
      "422 2.3667105779168196e-05\n",
      "423 2.2253150746109895e-05\n",
      "424 2.0920808310620487e-05\n",
      "425 1.9670085748657584e-05\n",
      "426 1.8491113223717548e-05\n",
      "427 1.7380149074597284e-05\n",
      "428 1.6337226043106057e-05\n",
      "429 1.5351146430475637e-05\n",
      "430 1.4427060705202166e-05\n",
      "431 1.3554426914197393e-05\n",
      "432 1.273661109735258e-05\n",
      "433 1.1965653357037809e-05\n",
      "434 1.1241626452829223e-05\n",
      "435 1.0559541806287598e-05\n",
      "436 9.917647730617318e-06\n",
      "437 9.314317139796913e-06\n",
      "438 8.746193998376839e-06\n",
      "439 8.213816727220546e-06\n",
      "440 7.711994840065017e-06\n",
      "441 7.24114806871512e-06\n",
      "442 6.796808065701043e-06\n",
      "443 6.380340892064851e-06\n",
      "444 5.988008069834905e-06\n",
      "445 5.620383490168024e-06\n",
      "446 5.274536306387745e-06\n",
      "447 4.949543381371768e-06\n",
      "448 4.643477041099686e-06\n",
      "449 4.357939360488672e-06\n",
      "450 4.0882664507080335e-06\n",
      "451 3.83427277483861e-06\n",
      "452 3.5968823794974014e-06\n",
      "453 3.3734265798557317e-06\n",
      "454 3.163559995300602e-06\n",
      "455 2.9664313387911534e-06\n",
      "456 2.7818427952297498e-06\n",
      "457 2.6080779207404703e-06\n",
      "458 2.445355676172767e-06\n",
      "459 2.2920432911632815e-06\n",
      "460 2.1488060610863613e-06\n",
      "461 2.0134532405791106e-06\n",
      "462 1.887484131657402e-06\n",
      "463 1.7687372064756346e-06\n",
      "464 1.6571817695876234e-06\n",
      "465 1.5529933534708107e-06\n",
      "466 1.4549268598784693e-06\n",
      "467 1.3628623491968028e-06\n",
      "468 1.2765531209879555e-06\n",
      "469 1.1959247103732196e-06\n",
      "470 1.1199848586329608e-06\n",
      "471 1.048511535373109e-06\n",
      "472 9.823277196119307e-07\n",
      "473 9.196261316901655e-07\n",
      "474 8.609466135567345e-07\n",
      "475 8.058726734816446e-07\n",
      "476 7.547255336248782e-07\n",
      "477 7.062482154651661e-07\n",
      "478 6.60851355860359e-07\n",
      "479 6.187038934513112e-07\n",
      "480 5.788908197246201e-07\n",
      "481 5.418565365289396e-07\n",
      "482 5.06887886331242e-07\n",
      "483 4.743505996884778e-07\n",
      "484 4.439857832494454e-07\n",
      "485 4.1506552861392265e-07\n",
      "486 3.883585577568738e-07\n",
      "487 3.6306533957031206e-07\n",
      "488 3.397432806195866e-07\n",
      "489 3.176143934524589e-07\n",
      "490 2.971041794808116e-07\n",
      "491 2.778483860765846e-07\n",
      "492 2.5964050109905656e-07\n",
      "493 2.4280058141812333e-07\n",
      "494 2.269695897894053e-07\n",
      "495 2.123401401377123e-07\n",
      "496 1.9833474595998268e-07\n",
      "497 1.854424596103854e-07\n",
      "498 1.7326755141766625e-07\n",
      "499 1.6196581498206797e-07\n"
     ]
    }
   ],
   "source": [
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable\n",
    "    # weights of the model). This is because by default, gradients are\n",
    "    # accumulated in buffers( i.e, not overwritten) whenever .backward()\n",
    "    # is called. Checkout docs of torch.autograd.backward for more details.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
